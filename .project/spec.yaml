specVersion: v2
meta:
  name: wb-llamafactory
  image: project-llamafactory
  description: ""
  labels: []
  createdOn: "2024-04-17T05:00:53Z"
  defaultBranch: main
layout:
- path: code/
  type: code
  storage: git
- path: models/
  type: models
  storage: gitlfs
- path: data/
  type: data
  storage: gitlfs
- path: data/scratch/
  type: data
  storage: gitignore
environment:
  base:
    registry: nvcr.io
    image: nvidia/ai-workbench/python-cuda122:1.0.3
    build_timestamp: "20231214221614"
    name: Python with CUDA 12.2
    supported_architectures: []
    cuda_version: "12.2"
    description: A Python Base with CUDA 12.2
    entrypoint_script: ""
    labels:
    - cuda12.2
    apps:
    - name: jupyterlab
      type: jupyterlab
      class: webapp
      start_command: jupyter lab --allow-root --port 8888 --ip 0.0.0.0 --no-browser
        --NotebookApp.base_url=\$PROXY_PREFIX --NotebookApp.default_url=/lab --NotebookApp.allow_origin='*'
      health_check_command: '[ \$(echo url=\$(jupyter lab list | head -n 2 | tail
        -n 1 | cut -f1 -d'' '' | grep -v ''Currently'' | sed "s@/?@/lab?@g") | curl
        -o /dev/null -s -w ''%{http_code}'' --config -) == ''200'' ]'
      stop_command: jupyter lab stop 8888
      user_msg: ""
      icon_url: ""
      webapp_options:
        autolaunch: true
        port: "8888"
        proxy:
          trim_prefix: false
        url_command: jupyter lab list | head -n 2 | tail -n 1 | cut -f1 -d' ' | grep
          -v 'Currently'
    programming_languages:
    - python3
    icon_url: ""
    image_version: 1.0.3
    os: linux
    os_distro: ubuntu
    os_distro_release: "22.04"
    schema_version: v2
    user_info:
      uid: ""
      gid: ""
      username: ""
    package_managers:
    - name: apt
      binary_path: /usr/bin/apt
      installed_packages:
      - curl
      - git
      - git-lfs
      - python3
      - gcc
      - python3-dev
      - python3-pip
      - vim
    - name: pip
      binary_path: /usr/local/bin/pip
      installed_packages:
      - jupyterlab==4.0.7
    package_manager_environment:
      name: ""
      target: ""
execution:
  apps:
  - name: llamafactory
    type: custom
    class: webapp
    start_command: cd $HOME/LLaMA-Factory && cp /project/code/train-web.py $HOME/LLaMA-Factory/src/train-web.py
      && PROXY_PREFIX=$PROXY_PREFIX $HOME/llama-factory-env/bin/python3 $HOME/LLaMA-Factory/src/train-web.py
    health_check_command: curl -f "http://localhost:7860/"
    stop_command: pkill -f "$HOME/llama-factory-env/bin/python3 $HOME/LLaMA-Factory/src/train-web.py"
    user_msg: ""
    icon_url: ""
    webapp_options:
      autolaunch: true
      port: "7860"
      proxy:
        trim_prefix: false
      url: http://localhost:7860/
  resources:
    gpu:
      requested: 1
    sharedMemoryMB: 1024
  secrets:
  - variable: HUGGING_FACE_HUB_TOKEN
    description: ""
  mounts:
  - type: project
    target: /project/
    description: Project directory
    options: rw
